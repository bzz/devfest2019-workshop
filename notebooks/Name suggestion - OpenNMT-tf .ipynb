{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Names suggestion\n",
    "\n",
    "Today we are going to show how to:\n",
    "* Extract function definitions\n",
    "* Highlight names and identifiers in function\n",
    "* extract features and labels\n",
    "* Train a tokenizer (BPE)\n",
    "* Prepare train & validation dataset for training a seq2seq model\n",
    "* Train seq2seq NMT model\n",
    "* Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import base64\n",
    "from bz2 import open as bz2_open\n",
    "from json import dumps as json_dumps, loads as json_loads\n",
    "\n",
    "import coloredlogs\n",
    "import pandas as pd\n",
    "import youtokentome as yttm\n",
    "\n",
    "from utils import DirsABC, FilesABC, Run, SUPPORTED_LANGUAGES, query_gitbase\n",
    "\n",
    "from enum import Enum\n",
    "from os import makedirs\n",
    "from os.path import join as path_join\n",
    "from typing import Union\n",
    "\n",
    "coloredlogs.install(level=\"WARNING\")\n",
    "logging.getLogger(\"matplotlib.axes._base\").setLevel(logging.INFO)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class Files(FilesABC, Enum):\n",
    "    FUNCTIONS = [\"functions.jsonl.bz2\"]\n",
    "    FUNC_ID_NAME = [\"functions_identifers_names.pkl.bz2\"]\n",
    "    BPE_MODEL = [\"bpe.model\"]\n",
    "    BPE_INPUT = [\"bpe_input.txt\"]\n",
    "    TRAIN_BODIES = [\"train.src\"]    \n",
    "    TRAIN_NAMES = [\"train.tgt\"]\n",
    "    VAL_BODIES = [\"val.src\"]\n",
    "    VAL_NAMES = [\"val.tgt\"]\n",
    "    ENC_TRAIN_BODIES = [\"train.bpe.src\"]\n",
    "    ENC_TRAIN_NAMES = [\"train.bpe.tgt\"]\n",
    "    ENC_VAL_BODIES = [\"val.bpe.src\"]\n",
    "    ENC_VAL_NAMES = [\"val.bpe.tgt\"]\n",
    "    TGT_VOCABULARY = [\"tgt.vocab\"]\n",
    "    SRC_VOCABULARY = [\"src.vocab\"]\n",
    "    MODEL_CONFIG = [\"model\", \"config.yml\"]    \n",
    "    MODEL_PRETRAINED = [\"pretrained\", \"ckpt-25000\"]\n",
    "    ENC_VAL_NAMES_PRED = [\"val.bpe.pred.tgt\"]\n",
    "    SAMPLE_ENC_VAL_BODIES = [\"sample_val.bpe.src\"]\n",
    "    SAMPLE_ENC_VAL_NAMES = [\"sample_val.bpe.tgt\"]\n",
    "\n",
    "class Dirs(DirsABC, Enum):\n",
    "    TF_MODELS = [\"tf\", \"models\"]\n",
    "    MODEL_RUN = [\"model\", \"run\"]\n",
    "\n",
    "    \n",
    "# Un-coment this at the end, to play with larger pre-processed data\n",
    "# run = Run(\"name-suggestion\", \"java-full\")\n",
    "\n",
    "run = Run(\"name-suggestion\", \"java-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_function_group(functions_path: str, limit: int = 0):    \n",
    "    sql = \"\"\"SELECT\n",
    "        files.repository_id as repository_id,\n",
    "        files.file_path as path,\n",
    "        files.blob_content as content,\n",
    "        UAST(files.blob_content, LANGUAGE(files.file_path, files.blob_content), '//uast:FunctionGroup') as functions\n",
    "    FROM files\n",
    "    NATURAL JOIN commit_files\n",
    "    NATURAL JOIN commits\n",
    "    NATURAL JOIN refs\n",
    "    WHERE\n",
    "        refs.ref_name= 'HEAD' and functions IS NOT NULL\n",
    "        AND LANGUAGE(files.file_path, files.blob_content) = 'Java'\n",
    "        AND NOT IS_VENDOR(file_path)\n",
    "        AND NOT IS_BINARY(file_path)\n",
    "    %s\n",
    "    \"\"\" % ( \"LIMIT %d\" % limit if limit > 0 else \"\" )\n",
    "    with bz2_open(functions_path, \"wt\", encoding=\"utf8\") as fh:\n",
    "        for row in query_gitbase(sql):\n",
    "            row[\"content\"] = base64.b64encode(row[\"content\"]).decode(\"utf-8\")\n",
    "            row[\"functions\"] = base64.b64encode(row[\"functions\"]).decode(\"utf-8\")\n",
    "            fh.write(\"%s\\n\" % json_dumps(row))\n",
    "\n",
    "\n",
    "extract_function_group(run.path(Files.FUNCTIONS), 3) # 21374 total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract function names and identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function_name(function_node):\n",
    "    func_name, func_name_pos = None, None\n",
    "    for node in function_node[\"Nodes\"]:\n",
    "        if node is None or \"@type\" not in node:\n",
    "            continue\n",
    "        if node[\"@type\"] == 'uast:Alias':\n",
    "            func_name = node[\"Name\"][\"Name\"]\n",
    "            func_name_pos = (node[\"Name\"][\"@pos\"][\"start\"][\"offset\"], node[\"Name\"][\"@pos\"][\"end\"][\"offset\"])\n",
    "    return func_name, func_name_pos\n",
    "\n",
    "def get_identifiers(node):\n",
    "    if (isinstance(node, dict) and \n",
    "        '@type' in node and \n",
    "        node['@type']  == 'uast:Identifier'):\n",
    "        yield node[\"Name\"], (node[\"@pos\"][\"start\"][\"offset\"], node[\"@pos\"][\"end\"][\"offset\"])\n",
    "    else:\n",
    "        if isinstance(node, dict):\n",
    "            for k in node:\n",
    "                yield from get_identifiers(node[k])\n",
    "        elif isinstance(node, list) or isinstance(node, tuple):\n",
    "            for n in node:\n",
    "                yield from get_identifiers(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data\n",
    "\n",
    "Inspect what is going to be a model feature and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import colored_text_by_pos, Colored, RED, GREEN\n",
    "from bblfsh.pyuast import decode as uast_decode\n",
    "\n",
    "def highlight_function_name_and_identifiers(functions_path: str, limit: int = 0):\n",
    "    with bz2_open(functions_path, \"rt\", encoding=\"utf8\") as fh_functions:\n",
    "        processed = 0\n",
    "        for row_str in fh_functions:\n",
    "            row = json_loads(row_str)\n",
    "            content = base64.b64decode(row[\"content\"]).decode('utf-8', 'replace')\n",
    "            func_group = uast_decode(base64.b64decode(row[\"functions\"]), format=0).load()\n",
    "\n",
    "            for func in func_group:\n",
    "                if limit > 0 and processed >= limit:\n",
    "                    return\n",
    "                processed += 1\n",
    "                identifiers = None\n",
    "                for node in func[\"Nodes\"]:        \n",
    "                    if node is None or \"@type\" not in node:\n",
    "                        continue\n",
    "                    if node[\"@type\"] == 'uast:Alias':\n",
    "                        func_body = node[\"Node\"][\"Body\"]\n",
    "                        body_identifiers = sorted(get_identifiers(func_body), key=lambda x: x[1][0])\n",
    "                func_name = get_function_name(func)\n",
    "                print(\"-\" * 20)\n",
    "\n",
    "                start_offset = func[\"@pos\"][\"start\"][\"offset\"]\n",
    "                end_offset = func[\"@pos\"][\"end\"][\"offset\"]\n",
    "                colored_texts = []\n",
    "                colored_texts.append(Colored(color=RED, position=func_name[1], start_offset=start_offset))\n",
    "                for bi in body_identifiers:\n",
    "                    colored_texts.append(Colored(color=GREEN, position=bi[1], start_offset=start_offset))\n",
    "                \n",
    "                print(colored_text_by_pos(content[start_offset:end_offset], colored_texts))\n",
    "\n",
    "\n",
    "highlight_function_name_and_identifiers(run.path(Files.FUNCTIONS), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and labels extraction\n",
    "\n",
    "Prepare raw model input: \n",
    " - X identifiers from the body,\n",
    " - Y lable, a name of the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def extract_functions_parallel(functions_path: str, limit: int = 0):\n",
    "\n",
    "    def read_function_group(functions_path: str, limit: int = 0):\n",
    "        with bz2_open(functions_path, \"rt\", encoding=\"utf-8\") as fh_functions:\n",
    "            processed = 0\n",
    "            for row_str in fh_functions:\n",
    "                row = json_loads(row_str)\n",
    "                func_group = base64.b64decode(row[\"functions\"])\n",
    "                if limit > 0 and processed >= limit:\n",
    "                    break\n",
    "                processed += 1\n",
    "                yield func_group\n",
    "\n",
    "    def process_function_group(func_group):\n",
    "        res = []\n",
    "        try:\n",
    "            func_group = uast_decode(func_group, format=0).load()\n",
    "\n",
    "            for func in func_group:\n",
    "                body_identifiers = None        \n",
    "                for node in func[\"Nodes\"]:        \n",
    "                    if node is None or \"@type\" not in node:\n",
    "                        continue\n",
    "                    if node[\"@type\"] == 'uast:Alias':\n",
    "                        func_body = node[\"Node\"][\"Body\"]\n",
    "                        body_identifiers = sorted(get_identifiers(func_body), key=lambda x: x[1][0])\n",
    "                if body_identifiers is None:\n",
    "                    continue\n",
    "                res.append(([i[0] for i in body_identifiers], get_function_name(func)[0]))\n",
    "        except:\n",
    "            print(\"decoding error\")\n",
    "        return res\n",
    "\n",
    "    function_group_res = Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(process_function_group)(fg) for fg in read_function_group(run.path(Files.FUNCTIONS), limit))\n",
    "    \n",
    "    res = itertools.chain.from_iterable(function_group_res)\n",
    "    deduplicated_res = filter(lambda x: x[0], set(map(lambda x: (tuple(x[0]), x[1]), res)))\n",
    "    \n",
    "    df = pd.DataFrame(deduplicated_res, columns = ['function_identifiers', 'function_name'])\n",
    "    df.to_pickle(run.path(Files.FUNC_ID_NAME))\n",
    "    del(df)\n",
    "\n",
    "\n",
    "extract_functions_parallel(run.path(Files.FUNCTIONS), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Byte Pair Encoding (BPE)\n",
    "\n",
    "In order to feed text data into the model (identifers) we need to represent it in the vector form.\n",
    "\n",
    "There are multiple ways to do so:\n",
    " 1. **word level**, assign a uniq number for every identifer\n",
    "    * *pro*: easy to implement (hashtable)\n",
    "    * *con*: huge (and rapidly growing) vocabulary size\n",
    "    * *con*: how to deal with Out Of Vacabulary (OOV) tokens? E.g by replace with \"-UNK-\"\n",
    " 2. **char level**, assign a uniq number for every char\n",
    "    * *pro*: small vocabulary size\n",
    "    * *pro*: no OOV\n",
    "    * *con*: model need to \"learn\" much more, e.g. to compose words first :/ \n",
    " 3. **sub-word level**, assign a uniq number for every sub-word (based on frequency)\n",
    "    * *pro*: small vocabulary size (hyperparameter)\n",
    "    * *pro*: easty to deal with OOV\n",
    "    * *con*: additional \"training\" step, harder to implement\n",
    "    \n",
    " \n",
    "We are going to use one particular sub-word level tokininzation algorithm called [Byte Pair Encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding) (BPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare BPE training data\n",
    "\n",
    "We use single vocabulary for both, identifiers and function names. In order to do so, we will need to train BPE tokenizer on a file that contains all identifiers and function names in plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env LANG=en_US.UTF-8\n",
    "%env LC_ALL=en_US.UTF-8\n",
    "\n",
    "def prepare_bpe_text_file(pkl_functions_path: str, text_file_path: str, limit: int = 0):\n",
    "    df = pd.read_pickle(pkl_functions_path)\n",
    "    with open(text_file_path, \"wt\") as text_file_fh:\n",
    "        for i, row in df.iterrows():\n",
    "            if limit > 0 and i >= limit:\n",
    "                break\n",
    "            text_file_fh.write(\" \".join(row[\"function_identifiers\"]))\n",
    "            text_file_fh.write(\" {}\\n\".format(row[\"function_name\"]))\n",
    "\n",
    "prepare_bpe_text_file(run.path(Files.FUNC_ID_NAME), run.path(Files.BPE_INPUT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BPE tokenizer\n",
    "\n",
    "Out of multile BPE impelementaitons we are going to use optimized C++ one form https://github.com/VKCOM/YouTokenToMe using its CLI interface and Python bindings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "\n",
    "!yttm bpe --data {run.path(Files.BPE_INPUT)} --model {run.path(Files.BPE_MODEL)} --vocab_size {vocab_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset on Training / Vaidation\n",
    "\n",
    "Create a dataset for training and a separate, holdout one for validation using handy [`model_selection` scikit-learn helper](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_pickle(run.path(Files.FUNC_ID_NAME))\n",
    "train_bodies, val_bodies, train_names, val_names = train_test_split(df.function_identifiers, df.function_name, \n",
    "                                                                    test_size=0.1, random_state=1989)\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset splits\n",
    "\n",
    "In the plain text format, suitable for further processing by [OpenNMT](http://opennmt.net/OpenNMT-tf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def save_as_text(output_path: str, data: pd.Series):\n",
    "    with open(output_path, \"wt\") as output_fd:\n",
    "        for row in tqdm(data):\n",
    "            if isinstance(row, str):\n",
    "                output_fd.write(row + \"\\n\")\n",
    "            else:\n",
    "                output_fd.write(\" \".join(row) + \"\\n\")\n",
    "            \n",
    "save_as_text(run.path(Files.TRAIN_BODIES), train_bodies)\n",
    "save_as_text(run.path(Files.TRAIN_NAMES), train_names)\n",
    "save_as_text(run.path(Files.VAL_BODIES), val_bodies)\n",
    "save_as_text(run.path(Files.VAL_NAMES), val_names)\n",
    "\n",
    "del(train_bodies); del(val_bodies); del(train_names); del(val_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode dataset\n",
    "\n",
    "Get vector represenation using the vocabulary from the trained BPE tokenizer, in the format compatible with [OpenNMT](http://opennmt.net/OpenNMT-tf/data.html#vocabulary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode dataset splits using BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe = yttm.BPE(model=run.path(Files.BPE_MODEL))\n",
    "\n",
    "def bpe_encode(input_path: str, output_path: str):\n",
    "    with open(output_path, \"w\") as output_fd, open(input_path, \"rt\") as input_fd:\n",
    "        data = input_fd.readlines()\n",
    "        for row in bpe.encode(data, output_type=yttm.OutputType.ID):\n",
    "            output_fd.write(\" \".join(map(str, row)) + \"\\n\")\n",
    "\n",
    "bpe_encode(run.path(Files.TRAIN_BODIES), run.path(Files.ENC_TRAIN_BODIES))\n",
    "bpe_encode(run.path(Files.TRAIN_NAMES), run.path(Files.ENC_TRAIN_NAMES))\n",
    "bpe_encode(run.path(Files.VAL_BODIES), run.path(Files.ENC_VAL_BODIES))\n",
    "bpe_encode(run.path(Files.VAL_NAMES), run.path(Files.ENC_VAL_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train seq2seq model\n",
    "\n",
    "* we will use [openNMT-tf](http://opennmt.net/OpenNMT-tf/)\n",
    "* prepare vocabularies (we will use functionality to train translation model from identifiers to function names)\n",
    "* train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenNMT requires to provide explicit vocabularies, so we build them out of BPE-encoded data\n",
    "def generate_build_vocab(save_vocab_loc, input_text, vocab_size=vocab_size):\n",
    "    return \"onmt-build-vocab --size %s --save_vocab %s %s\" % (vocab_size, \n",
    "                                                              save_vocab_loc,\n",
    "                                                              input_text)\n",
    "\n",
    "if not os.path.exists(run.path(Files.SRC_VOCABULARY)):\n",
    "    print(\"Generating vocabularies\")\n",
    "    # in case of pretrained model we reuse vocabulary\n",
    "    cmd = generate_build_vocab(save_vocab_loc=run.path(Files.SRC_VOCABULARY),\n",
    "                               input_text=run.path(Files.ENC_TRAIN_BODIES),\n",
    "                               vocab_size=vocab_size + 10)\n",
    "    ! {cmd}\n",
    "\n",
    "    cmd = generate_build_vocab(save_vocab_loc=run.path(Files.TGT_VOCABULARY),\n",
    "                               input_text=run.path(Files.ENC_TRAIN_NAMES),\n",
    "                               vocab_size=vocab_size + 10)\n",
    "    ! {cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = run.path(Dirs.MODEL_RUN)\n",
    "\n",
    "# prepare config file for model\n",
    "config_yaml = run.path(Files.MODEL_CONFIG)\n",
    "# this directory will contain evaluation results of the model, checkpoints and so on\n",
    "yaml_content = \"model_dir: %s \\n\" % model_dir\n",
    "\n",
    "# where the data is\n",
    "yaml_content += \"\"\"\n",
    "data:\n",
    "  train_features_file: %s\n",
    "  train_labels_file: %s\n",
    "  eval_features_file: %s\n",
    "  eval_labels_file: %s\n",
    "  source_vocabulary: %s\n",
    "  target_vocabulary: %s\n",
    "\"\"\" % (run.path(Files.ENC_TRAIN_BODIES), \n",
    "       run.path(Files.ENC_TRAIN_NAMES),\n",
    "       run.path(Files.ENC_VAL_BODIES), \n",
    "       run.path(Files.ENC_VAL_NAMES),\n",
    "       run.path(Files.SRC_VOCABULARY), \n",
    "       run.path(Files.TGT_VOCABULARY))\n",
    "\n",
    "# other configurations that affect training process\n",
    "yaml_content += \"\"\"\n",
    "train:\n",
    "  # (optional when batch_type=tokens) If not set, the training will search the largest\n",
    "  # possible batch size.\n",
    "  batch_size: 32\n",
    "\n",
    "eval:\n",
    "  # (optional) The batch size to use (default: 32).\n",
    "  batch_size: 128\n",
    "\n",
    "  # (optional) Evaluate every this many steps (default: 5000).\n",
    "  steps: 5000\n",
    "\n",
    "  # (optional) Save evaluation predictions in model_dir/eval/.\n",
    "  save_eval_predictions: false\n",
    "  # (optional) Evalutator or list of evaluators that are called on the saved evaluation predictions.\n",
    "  # Available evaluators: bleu, rouge\n",
    "  external_evaluators: bleu\n",
    "\n",
    "  # (optional) Export a SavedModel when a metric has the best value so far (default: null).\n",
    "  export_on_best: bleu\n",
    "\n",
    "  # (optional) Early stopping condition.\n",
    "  # Should be read as: stop the training if \"metric\" did not improve more\n",
    "  # than \"min_improvement\" in the last \"steps\" evaluations.\n",
    "  early_stopping:\n",
    "    # (optional) The target metric name (default: \"loss\").\n",
    "    metric: bleu\n",
    "    # (optional) The metric should improve at least by this much to be considered as an improvement (default: 0)\n",
    "    min_improvement: 0.01\n",
    "    steps: 2\n",
    "\"\"\"\n",
    "\n",
    "with open(config_yaml, \"w\") as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Using a 2 layer encode-decoder LSTM model architecture by setting `--model_type LuongAttention` as described by [Minh-Thang Luong et all, 2015](https://arxiv.org/abs/1508.04025)\n",
    "\n",
    "### Performance on GPU vs CPU:\n",
    "* CPU with 4 cores: `source words/s = 104, target words/s = 34`\n",
    "* 1080 GPU: `source words/s = 6959, target words/s = 1434`\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to launch training\n",
    "GPU_USE = False\n",
    "if not GPU_USE:\n",
    "    train_cmd = \"\"\"\n",
    "    onmt-main --model_type LuongAttention \\\n",
    "    --config %s --auto_config train --with_eval\"\"\" % config_yaml\n",
    "    ! {train_cmd}\n",
    "\n",
    "# in case of GPU you can specify CUDA_VISIBLE_DEVICES & number of GPUs to use\n",
    "if GPU_USE:\n",
    "    cmd_gpu = \"\"\"\n",
    "    CUDA_VISIBLE_DEVICES=%s onmt-main --model_type LuongAttention \\\n",
    "    --config %s --auto_config train --with_eval --num_gpus %s\"\"\" % (\"0,1\", config_yaml, 2)\n",
    "    ! {cmd_gpu}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la {model_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "* we will use pretrained on several GPUs model to save time\n",
    "* predictions will be saved to file \n",
    "* predicted BPE ids will be converted back to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = None\n",
    "\n",
    "# Put your checkoint number insteaf of XXX\n",
    "# Comment this, in oredr to use an already pre-trained model instead\n",
    "pretrained_model = \"{}/ckpt-0\".format(model_dir)\n",
    "\n",
    "if pretrained_model is None:\n",
    "    pretrained_model = run.path(Files.MODEL_PRETRAINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit number of samples to process\n",
    "!head -50 {run.path(Files.ENC_VAL_BODIES)} > {run.path(Files.SAMPLE_ENC_VAL_BODIES)}\n",
    "!head -50 {run.path(Files.ENC_VAL_NAMES)} > {run.path(Files.SAMPLE_ENC_VAL_NAMES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_cmd = \"\"\"onmt-main \\\n",
    "--config %s --auto_config --model_type LuongAttention \\\n",
    "--checkpoint_path %s \\\n",
    "infer \\\n",
    "--features_file %s \\\n",
    "--predictions_file %s\n",
    "\"\"\" % (config_yaml, pretrained_model,\n",
    "                           run.path(Files.SAMPLE_ENC_VAL_BODIES), \n",
    "                           run.path(Files.ENC_VAL_NAMES_PRED),\n",
    "                           )\n",
    "! {predict_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {run.path(Files.ENC_VAL_NAMES_PRED)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ids = []\n",
    "with open(run.path(Files.ENC_VAL_NAMES_PRED), \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        pred_ids.append(list(map(int, line.split())))\n",
    "\n",
    "pred_val_function_names = bpe.decode(pred_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ids = []\n",
    "with open(run.path(Files.SAMPLE_ENC_VAL_NAMES), \"r\") as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "        gt_ids.append(list(map(int, line.split())))\n",
    "gt_val_function_names = bpe.decode(gt_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And finally let's see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gt_name, pred_name in zip(gt_val_function_names, pred_val_function_names):\n",
    "    print(\"%s | %s\" % (gt_name, pred_name))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality\n",
    "\n",
    "This is a very simplistic base line model, wich misses a lot of context information to make a decidions:\n",
    "* roles of identifiers\n",
    "* structural information \n",
    "* arguments to function\n",
    "\n",
    "Many more improvements were proposed recently [code2vec](https://github.com/tech-srl/code2vec), [GGNNs](). etc.\n",
    "\n",
    "Check [github.com/src-d/awesome-machine-learning-on-source-code](https://github.com/src-d/awesome-machine-learning-on-source-code) to learn about State Of the Art (SOtA) models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
